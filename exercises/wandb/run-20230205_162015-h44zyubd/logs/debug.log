2023-02-05 16:20:15,261 INFO    MainThread:15440 [wandb_setup.py:_flush():68] Configure stats pid to 15440
2023-02-05 16:20:15,261 INFO    MainThread:15440 [wandb_setup.py:_flush():68] Loading settings from C:\Users\calsm\.config\wandb\settings
2023-02-05 16:20:15,261 INFO    MainThread:15440 [wandb_setup.py:_flush():68] Loading settings from c:\Users\calsm\Documents\AI Alignment\ARENA\DEEP_LEARNING_INTRO_MATERIAL\exercises\wandb\settings
2023-02-05 16:20:15,261 INFO    MainThread:15440 [wandb_setup.py:_flush():68] Loading settings from environment variables: {'_require_service': 'True'}
2023-02-05 16:20:15,261 INFO    MainThread:15440 [wandb_setup.py:_flush():68] Inferring run settings from compute environment: {'program_relpath': 'exercises\\part4_optimization_solutions.py', 'program': 'c:\\Users\\calsm\\Documents\\AI Alignment\\ARENA\\DEEP_LEARNING_INTRO_MATERIAL\\exercises\\part4_optimization_solutions.py'}
2023-02-05 16:20:15,262 INFO    MainThread:15440 [wandb_init.py:_log_setup():478] Logging user logs to c:\Users\calsm\Documents\AI Alignment\ARENA\DEEP_LEARNING_INTRO_MATERIAL\exercises\wandb\run-20230205_162015-h44zyubd\logs\debug.log
2023-02-05 16:20:15,262 INFO    MainThread:15440 [wandb_init.py:_log_setup():479] Logging internal logs to c:\Users\calsm\Documents\AI Alignment\ARENA\DEEP_LEARNING_INTRO_MATERIAL\exercises\wandb\run-20230205_162015-h44zyubd\logs\debug-internal.log
2023-02-05 16:20:15,262 INFO    MainThread:15440 [wandb_init.py:init():518] calling init triggers
2023-02-05 16:20:15,262 INFO    MainThread:15440 [wandb_init.py:init():521] wandb.init called with sweep_config: {}
config: {'trainset': Dataset CIFAR10
    Number of datapoints: 50000
    Root location: ./data
    Split: Train
    StandardTransform
Transform: Compose(
               ToTensor()
               Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
           ), 'testset': Dataset CIFAR10
    Number of datapoints: 10000
    Root location: ./data
    Split: Test
    StandardTransform
Transform: Compose(
               ToTensor()
               Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
           ), 'epochs': ResNetTrainingArgs(trainset=Dataset CIFAR10
    Number of datapoints: 50000
    Root location: ./data
    Split: Train
    StandardTransform
Transform: Compose(
               ToTensor()
               Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
           ), testset=Dataset CIFAR10
    Number of datapoints: 10000
    Root location: ./data
    Split: Test
    StandardTransform
Transform: Compose(
               ToTensor()
               Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
           ), epochs=3, batch_size=512, loss_fn=CrossEntropyLoss(), optimizer=<class 'torch.optim.adam.Adam'>, optimizer_args=(), device='cuda', filename_save_model='models/part4_resnet.pt', subset=5), 'batch_size': 512, 'loss_fn': CrossEntropyLoss(), 'optimizer': <class 'torch.optim.adam.Adam'>, 'optimizer_args': (), 'device': 'cuda', 'filename_save_model': 'models/part4_resnet.pt', 'subset': 1}
2023-02-05 16:20:15,262 INFO    MainThread:15440 [wandb_init.py:init():537] re-initializing run, found existing run on stack: sswj3b6i
2023-02-05 16:20:15,264 INFO    MainThread:15440 [wandb_run.py:_finish():1844] finishing run callum-mcdougall/part4_optimization_resnet/sswj3b6i
2023-02-05 16:20:15,264 INFO    MainThread:15440 [jupyter.py:save_history():449] not saving jupyter history
2023-02-05 16:20:15,264 INFO    MainThread:15440 [jupyter.py:save_ipynb():379] not saving jupyter notebook
2023-02-05 16:20:15,264 INFO    MainThread:15440 [wandb_init.py:_jupyter_teardown():410] cleaning up jupyter logic
2023-02-05 16:20:15,264 INFO    MainThread:15440 [wandb_run.py:_atexit_cleanup():2070] got exitcode: 0
2023-02-05 16:20:15,265 INFO    MainThread:15440 [wandb_run.py:_restore():2053] restore
2023-02-05 16:20:15,265 INFO    MainThread:15440 [wandb_run.py:_restore():2059] restore done
2023-02-05 16:20:22,787 INFO    MainThread:15440 [wandb_run.py:_footer_history_summary_info():3427] rendering history
2023-02-05 16:20:22,795 INFO    MainThread:15440 [wandb_run.py:_footer_history_summary_info():3459] rendering summary
2023-02-05 16:20:22,800 INFO    MainThread:15440 [wandb_run.py:_footer_sync_info():3383] logging synced files
2023-02-05 16:20:22,804 INFO    MainThread:15440 [wandb_init.py:init():571] starting backend
2023-02-05 16:20:22,805 INFO    MainThread:15440 [wandb_init.py:init():575] setting up manager
2023-02-05 16:20:22,807 INFO    MainThread:15440 [backend.py:_multiprocessing_setup():106] multiprocessing start_methods=spawn, using: spawn
2023-02-05 16:20:22,809 INFO    MainThread:15440 [wandb_init.py:init():582] backend started and connected
2023-02-05 16:20:22,814 INFO    MainThread:15440 [wandb_run.py:_label_probe_notebook():1202] probe notebook
2023-02-05 16:20:22,815 INFO    MainThread:15440 [wandb_run.py:_label_probe_notebook():1212] Unable to probe notebook: 'NoneType' object has no attribute 'get'
2023-02-05 16:20:22,815 INFO    MainThread:15440 [wandb_init.py:init():670] updated telemetry
2023-02-05 16:20:22,869 INFO    MainThread:15440 [wandb_init.py:init():710] communicating run to backend with 60.0 second timeout
2023-02-05 16:20:24,021 INFO    MainThread:15440 [wandb_run.py:_on_init():2121] communicating current version
2023-02-05 16:20:24,061 INFO    MainThread:15440 [wandb_run.py:_on_init():2125] got version response 
2023-02-05 16:20:24,061 INFO    MainThread:15440 [wandb_init.py:init():758] starting run threads in backend
2023-02-05 16:20:24,181 INFO    MainThread:15440 [wandb_run.py:_console_start():2101] atexit reg
2023-02-05 16:20:24,181 INFO    MainThread:15440 [wandb_run.py:_redirect():1959] redirect: SettingsConsole.WRAP_RAW
2023-02-05 16:20:24,181 INFO    MainThread:15440 [wandb_run.py:_redirect():2024] Wrapping output streams.
2023-02-05 16:20:24,181 INFO    MainThread:15440 [wandb_run.py:_redirect():2046] Redirects installed.
2023-02-05 16:20:24,182 INFO    MainThread:15440 [wandb_init.py:init():798] run started, returning control to user process
2023-02-05 16:20:24,354 INFO    MainThread:15440 [wandb_watch.py:watch():51] Watching
2023-02-05 16:20:57,827 INFO    MainThread:15440 [wandb_setup.py:_flush():68] Configure stats pid to 15440
2023-02-05 16:20:57,827 INFO    MainThread:15440 [wandb_setup.py:_flush():68] Loading settings from C:\Users\calsm\.config\wandb\settings
2023-02-05 16:20:57,827 INFO    MainThread:15440 [wandb_setup.py:_flush():68] Loading settings from c:\Users\calsm\Documents\AI Alignment\ARENA\DEEP_LEARNING_INTRO_MATERIAL\exercises\wandb\settings
2023-02-05 16:20:57,827 INFO    MainThread:15440 [wandb_setup.py:_flush():68] Loading settings from environment variables: {'_require_service': 'True'}
2023-02-05 16:20:57,828 INFO    MainThread:15440 [wandb_setup.py:_flush():68] Inferring run settings from compute environment: {'program_relpath': 'exercises\\part4_optimization_solutions.py', 'program': 'c:\\Users\\calsm\\Documents\\AI Alignment\\ARENA\\DEEP_LEARNING_INTRO_MATERIAL\\exercises\\part4_optimization_solutions.py'}
2023-02-05 16:20:57,828 INFO    MainThread:15440 [wandb_init.py:_log_setup():478] Logging user logs to c:\Users\calsm\Documents\AI Alignment\ARENA\DEEP_LEARNING_INTRO_MATERIAL\exercises\wandb\run-20230205_162057-u45bbp5m\logs\debug.log
2023-02-05 16:20:57,828 INFO    MainThread:15440 [wandb_init.py:_log_setup():479] Logging internal logs to c:\Users\calsm\Documents\AI Alignment\ARENA\DEEP_LEARNING_INTRO_MATERIAL\exercises\wandb\run-20230205_162057-u45bbp5m\logs\debug-internal.log
2023-02-05 16:20:57,828 INFO    MainThread:15440 [wandb_init.py:_jupyter_setup():428] configuring jupyter hooks <wandb.sdk.wandb_init._WandbInit object at 0x000002289192F790>
2023-02-05 16:20:57,829 INFO    MainThread:15440 [wandb_init.py:init():518] calling init triggers
2023-02-05 16:20:57,829 INFO    MainThread:15440 [wandb_init.py:init():521] wandb.init called with sweep_config: {}
config: {'trainset': Dataset CIFAR10
    Number of datapoints: 50000
    Root location: ./data
    Split: Train
    StandardTransform
Transform: Compose(
               ToTensor()
               Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
           ), 'testset': Dataset CIFAR10
    Number of datapoints: 10000
    Root location: ./data
    Split: Test
    StandardTransform
Transform: Compose(
               ToTensor()
               Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
           ), 'epochs': 3, 'batch_size': 512, 'loss_fn': CrossEntropyLoss(), 'optimizer': <class 'torch.optim.adam.Adam'>, 'optimizer_args': (), 'device': 'cuda', 'filename_save_model': 'models/part4_resnet.pt', 'subset': 1}
2023-02-05 16:20:57,829 INFO    MainThread:15440 [wandb_init.py:init():537] re-initializing run, found existing run on stack: h44zyubd
2023-02-05 16:20:57,830 INFO    MainThread:15440 [wandb_run.py:_finish():1844] finishing run callum-mcdougall/part4_model_resnet/h44zyubd
2023-02-05 16:20:57,832 INFO    MainThread:15440 [wandb_run.py:_atexit_cleanup():2070] got exitcode: 0
2023-02-05 16:20:57,832 INFO    MainThread:15440 [wandb_run.py:_restore():2053] restore
2023-02-05 16:20:57,832 INFO    MainThread:15440 [wandb_run.py:_restore():2059] restore done
2023-02-05 16:21:04,343 INFO    MainThread:15440 [wandb_run.py:_footer_history_summary_info():3427] rendering history
2023-02-05 16:21:04,343 INFO    MainThread:15440 [wandb_run.py:_footer_history_summary_info():3459] rendering summary
2023-02-05 16:21:04,345 INFO    MainThread:15440 [wandb_run.py:_footer_sync_info():3383] logging synced files
